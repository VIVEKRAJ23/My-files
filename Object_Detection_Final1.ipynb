{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzqMYO9s3HtQ"
   },
   "source": [
    "# Object Detection from Images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "UrOjA1JMsJBm"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_test,y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {},
    "colab_type": "code",
    "id": "emU1tLg-sJBw"
   },
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2fdcfbcc206f85ccb00a863eac2e88f11f0897f1",
    "colab": {},
    "colab_type": "code",
    "id": "dsOTWjQysJCT"
   },
   "outputs": [],
   "source": [
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ef4c55aea55321070454aff38981a7935eb56b3",
    "colab": {},
    "colab_type": "code",
    "id": "CQy30hkysJCd",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03e77e5362c3d161422f0dd854374b5888835a3f",
    "colab": {},
    "colab_type": "code",
    "id": "JBMoV4SksJCm"
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-scaling so that all the pixel values lie within 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8c653b402e1076d543443823e938e1d1d749112f",
    "colab": {},
    "colab_type": "code",
    "id": "6K67abHHsJDO"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')/255\n",
    "x_test = x_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8682ee259c3346121fb067d2abecb92a82536163",
    "colab": {},
    "colab_type": "code",
    "id": "bG9sZItbsJDW"
   },
   "outputs": [],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4992fbeb257cac04fcccb65b108637e8117a77fe",
    "colab": {},
    "colab_type": "code",
    "id": "0X1Z-thMsJDg"
   },
   "outputs": [],
   "source": [
    "no_of_classes = len(np.unique(y_train))\n",
    "no_of_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming it into One-hot Encoded form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "a12c157822c4d43a11557c869ef30d6822d56d1b",
    "colab": {},
    "colab_type": "code",
    "id": "LXV5UBpisJDw"
   },
   "outputs": [],
   "source": [
    "y_train = tensorflow.keras.utils.to_categorical(y_train,no_of_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test,no_of_classes)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing our training set into 2 sets - train and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f596de6d31eec41be9e3981b38f842abb2a6ef06",
    "colab": {},
    "colab_type": "code",
    "id": "2kzlRdlysJD2"
   },
   "outputs": [],
   "source": [
    "x_train,x_valid = x_train[5000:],x_train[:5000]\n",
    "y_train,y_valid = y_train[5000:],y_train[:5000]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae8017bfd969d8a7886fd556a611db5155b22b19",
    "colab": {},
    "colab_type": "code",
    "id": "RKV7i30DsJD7"
   },
   "outputs": [],
   "source": [
    "print(x_valid.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53c9a5e177e2c2d30729d36833e960e3a88009cd",
    "colab": {},
    "colab_type": "code",
    "id": "ntVJPPXUsJEC"
   },
   "outputs": [],
   "source": [
    "#Showing the pictures of First 20 images from training data set\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(25):\n",
    "    ax = fig.add_subplot(5,5,i+1,xticks=[],yticks=[])\n",
    "    ax.imshow(np.squeeze(x_train[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58a299ebd217d5e9c6339f89c342a64ba1f9eca8",
    "colab": {},
    "colab_type": "code",
    "id": "w3nD3fDPsJEL"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,Dense,Flatten,Dropout,MaxPooling2D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size = 2, padding = 'same',activation = 'relu',input_shape=(32,32,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size = 2, padding = 'same',activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size = 2, padding = 'same',activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500,activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc6f93635fa9f1456d532bb0e273e4e2d833a486",
    "colab": {},
    "colab_type": "code",
    "id": "Rz_zQzRysJES"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss ='categorical_crossentropy',metrics=['accuracy'])\n",
    "print('Model compiled!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training the model - 3..... 2...... 1...... Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a1c85173140720d0b72fc693af19f16a3136e35",
    "colab": {},
    "colab_type": "code",
    "id": "MAuuWMN_sJEY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath = 'best_model_.h5',save_best_only = True,verbose=1) #Save the best model in the file path\n",
    "\n",
    "history = model.fit(x_train,y_train,batch_size=32, epochs = 15,\n",
    "          validation_data=(x_valid,y_valid),\n",
    "          callbacks=[checkpoint],\n",
    "          verbose=2, \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the accuracy score of the best model on our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "61130dbb753426b29de4f838d472920b3414e0a8",
    "colab": {},
    "colab_type": "code",
    "id": "s7HBRj3XsJEd"
   },
   "outputs": [],
   "source": [
    "model.load_weights('Best_Basic_Model.h5')\n",
    "score = model.evaluate(x_test,y_test,verbose=0)\n",
    "score[1]\n",
    "\n",
    "#Accuracy ranging from 73% to 78%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the accuracy and loss over the epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8d5e29c314d1dcead75215914873c31e9ca2e5e0",
    "colab": {},
    "colab_type": "code",
    "id": "Kq9vMyNxsJEi"
   },
   "outputs": [],
   "source": [
    "plt.figure(1)  \n",
    "   \n",
    "#summarizing history for accuracy  \n",
    "\n",
    "plt.subplot(211)  \n",
    "plt.plot(history.history['accuracy'])  \n",
    "plt.plot(history.history['val_accuracy'])  \n",
    "plt.title('Model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "   \n",
    "\n",
    "#summarizing history for loss  \n",
    "   \n",
    "plt.subplot(212)  \n",
    "plt.plot(history.history['loss'])  \n",
    "plt.plot(history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper left')  \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEX1YEHAP6yt"
   },
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained Model using VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXhRduqSP68X"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import rand\n",
    "pd.options.display.max_colwidth = 600\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "# # Matplot Imports\n",
    "# import matplotlib.pyplot as plt\n",
    "# params = {'legend.fontsize': 'x-large',\n",
    "#           'figure.figsize': (15, 5),\n",
    "#           'axes.labelsize': 'x-large',\n",
    "#           'axes.titlesize':'x-large',\n",
    "#           'xtick.labelsize':'x-large',\n",
    "#           'ytick.labelsize':'x-large'}\n",
    "\n",
    "# plt.rcParams.update(params)\n",
    "# %matplotlib inline\n",
    "\n",
    "# # pandas display data frames as tables\n",
    "# from IPython.display import display, HTML\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "conyUhAKP6_z"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras.datasets import cifar10\n",
    "from keras.engine import Model\n",
    "from keras.applications import vgg16 as vgg\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8aKHDoo1P7DQ"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "NUM_CLASSES = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I am using VGG16 as a feature extractor, the minimum size of an image it takes is 48x48."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fu_XBQkoP7GY"
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage import data\n",
    "x = data.camera()\n",
    "X_train = np.array([resize(x, (48, 48)) for x in x_train])\n",
    "X_val = np.array([resize(x, (48, 48)) for x in x_valid])\n",
    "X_test = np.array([resize(x, (48, 48)) for x in x_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the Model\n",
    "\n",
    "* Loading VGG16 without the top classification layer\n",
    "* Preparing a custom classifier\n",
    "* Stacking both models on top of each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y07Uzk4oRu71"
   },
   "outputs": [],
   "source": [
    "vgg_model = vgg.VGG16(weights='imagenet', \n",
    "                       include_top=False, \n",
    "                       input_shape=(48, 48, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Extracting the last layer from third block of VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJ_EambLSqme"
   },
   "outputs": [],
   "source": [
    "last = vgg_model.get_layer('block3_pool').output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Adding Classification layers on top of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rM9BuzWXSqt1"
   },
   "outputs": [],
   "source": [
    "x = GlobalAveragePooling2D()(last)\n",
    "x= BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "pred = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = Model(vgg_model.input, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only training the custom classifier, we freeze the layers of VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vx0ZVNUASrEy"
   },
   "outputs": [],
   "source": [
    "for layer in vgg_model.layers:\n",
    "     layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling VGG16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vBMVMnLSqqF"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Model compiled!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsNtvI-DSqd8"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oCfSPVOXTq2j"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ywP6u7gPTxbh"
   },
   "outputs": [],
   "source": [
    "# For Training Data\n",
    "\n",
    "train_datagen.fit(X_train)\n",
    "train_generator = train_datagen.flow(X_train,\n",
    "                                     y_train, \n",
    "                                     batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zPYmeM0VT1B4"
   },
   "outputs": [],
   "source": [
    "# For Validation Data\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "val_datagen.fit(X_val)\n",
    "val_generator = val_datagen.flow(X_val,\n",
    "                                 y_valid,\n",
    "                                 batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AwNkICAwUj1P"
   },
   "outputs": [],
   "source": [
    "train_steps_per_epoch = X_train.shape[0] // BATCH_SIZE\n",
    "val_steps_per_epoch = X_val.shape[0] // BATCH_SIZE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start training the VGG16 model - 3..... 2...... 1...... Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tyla05HYX3bL"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint1 = ModelCheckpoint(filepath = 'Best_Model_Pretrained_.h5',save_best_only = True,verbose=1)\n",
    "\n",
    "history1 = model.fit(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=val_steps_per_epoch,\n",
    "                              epochs=EPOCHS,\n",
    "                              callbacks=[checkpoint1],\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the accuracy score of the best model on our test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gmo7mwd5VuAA"
   },
   "outputs": [],
   "source": [
    "model.load_weights('Best_Model_Pretrained_.h5')\n",
    "score1 = model.evaluate(X_test,y_test,verbose=0)\n",
    "score1[1]\n",
    "\n",
    "# Getting accuracy of around 83% on Epoch=40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the accuracy and loss over the epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JxJNtxPYiVa8"
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(35, 7))\n",
    "t = f.suptitle('Deep Neural Net Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epochs = list(range(1,EPOCHS+1))\n",
    "ax1.plot(epochs, history1.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epochs, history1.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epochs, history1.history['loss'], label='Train Loss')\n",
    "ax2.plot(epochs, history1.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(epochs)\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OyQrewEWMGzV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Object Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
