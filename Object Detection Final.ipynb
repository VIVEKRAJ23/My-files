{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Object Detection.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VIVEKRAJ23/My-files/blob/master/Object%20Detection%20Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzqMYO9s3HtQ",
        "colab_type": "text"
      },
      "source": [
        "# *Object Detection*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "41b96520e45796f57d4645822c3bb635955fbe22",
        "id": "S7ieqEuJsJBk",
        "colab_type": "text"
      },
      "source": [
        "In this kernel, I will be building a CNN from scratch for CIFAR 10 dataset loaded from keras. It is a dataset of 50,000 32x32 color training images, labeled over 10 categories, and 10,000 test images. We will try to find the best CNN model for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "UrOjA1JMsJBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import tensorflow as tf\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "# from tensorflow.keras import datasets,models,layers\n",
        "# data = tf.keras.datasets.cifar10\n",
        "\n",
        "(x_train,y_train),(x_test,y_test) = cifar10.load_data() #load cifar 10 dataset from keras\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRqVHZhVicXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (train_images, train_labels), (test_images, test_labels) = data.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "emU1tLg-sJBw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's see the dimen of our training data!\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "#Looks like x_train has 50000 entries of dimen 32*32*3 and y_train has 50000 entries of dimen 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "2fdcfbcc206f85ccb00a863eac2e88f11f0897f1",
        "id": "dsOTWjQysJCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's see the dimen of our testing data!\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "# As expected, similar to the shape of testing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "1ef4c55aea55321070454aff38981a7935eb56b3",
        "scrolled": false,
        "id": "CQy30hkysJCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# how about we try to see the contents. Let's look at the first element of x_train\n",
        "x_train[0]\n",
        "# It is simply an array of numbers - Note that these numbers denote the pixel values(0-255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "03e77e5362c3d161422f0dd854374b5888835a3f",
        "id": "JBMoV4SksJCm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train\n",
        "# We know that all the images are labelled over 10 categories. \n",
        "#So, the y_train is a number between 0 to 10 where each number depicts one category."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8c653b402e1076d543443823e938e1d1d749112f",
        "id": "6K67abHHsJDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# time to re-scale so that all the pixel values lie within 0 to 1\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8682ee259c3346121fb067d2abecb92a82536163",
        "id": "bG9sZItbsJDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's see how it looks after re-scale\n",
        "x_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4992fbeb257cac04fcccb65b108637e8117a77fe",
        "id": "0X1Z-thMsJDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_of_classes = len(np.unique(y_train))\n",
        "no_of_classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "a12c157822c4d43a11557c869ef30d6822d56d1b",
        "id": "LXV5UBpisJDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras\n",
        "# here, we are transforming y_train and y_test to be an array of size 10.\n",
        "# The value of y_train/y_test as we saw earlier was a number from 0 to 9 each depicting one category.\n",
        "# The value of y is represented by 1 in the corresponding array position and others are set to 0. \n",
        "# So, each row has only one item whose value will be 1 which depicts the category.\n",
        "y_train = tensorflow.keras.utils.to_categorical(y_train,no_of_classes)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test,no_of_classes)\n",
        "y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "f596de6d31eec41be9e3981b38f842abb2a6ef06",
        "id": "2kzlRdlysJD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we are going to divide our training set into 2 sets - train and validation.\n",
        "x_train,x_valid = x_train[5000:],x_train[:5000]\n",
        "y_train,y_valid = y_train[5000:],y_train[:5000]\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "ae8017bfd969d8a7886fd556a611db5155b22b19",
        "id": "RKV7i30DsJD7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(x_valid.shape)\n",
        "print(y_valid.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "53c9a5e177e2c2d30729d36833e960e3a88009cd",
        "id": "ntVJPPXUsJEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#let's visualize the first 50 images of training set\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(20,20))\n",
        "for i in range(25):\n",
        "    ax = fig.add_subplot(5,5,i+1,xticks=[],yticks=[])\n",
        "    ax.imshow(np.squeeze(x_train[i]))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "58a299ebd217d5e9c6339f89c342a64ba1f9eca8",
        "id": "w3nD3fDPsJEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Time to create our model ! Simple use of convolutional and max pooling layers.\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,Dense,Flatten,Dropout,MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=16, kernel_size = 2, padding = 'same',activation = 'relu',input_shape=(32,32,3)))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size = 2, padding = 'same',activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size = 2, padding = 'same',activation = 'relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500,activation='relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "cc6f93635fa9f1456d532bb0e273e4e2d833a486",
        "id": "Rz_zQzRysJES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compile the model\n",
        "model.compile(optimizer = 'adam', loss ='categorical_crossentropy',metrics=['accuracy'])\n",
        "print('compiled!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYIp5fQkGzMj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# datagen = ImageDataGenerator(\n",
        "#         featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "#         samplewise_center=False,  # set each sample mean to 0\n",
        "#         featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "#         samplewise_std_normalization=False,  # divide each input by its std\n",
        "#         zca_whitening=False,  # apply ZCA whitening\n",
        "#         zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "#         rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "#         # randomly shift images horizontally (fraction of total width)\n",
        "#         width_shift_range=0.1,\n",
        "#         # randomly shift images vertically (fraction of total height)\n",
        "#         height_shift_range=0.1,\n",
        "#         shear_range=0.,  # set range for random shear\n",
        "#         zoom_range=0.,  # set range for random zoom\n",
        "#         channel_shift_range=0.,  # set range for random channel shifts\n",
        "#         # set mode for filling points outside the input boundaries\n",
        "#         fill_mode='nearest',\n",
        "#         cval=0.,  # value used for fill_mode = \"constant\"\n",
        "#         horizontal_flip=True,  # randomly flip images\n",
        "#         vertical_flip=False,  # randomly flip images\n",
        "#         # set rescaling factor (applied before any other transformation)\n",
        "#         rescale=None,\n",
        "#         # set function that will be applied on each input\n",
        "#         preprocessing_function=None,\n",
        "#         # image data format, either \"channels_first\" or \"channels_last\"\n",
        "#         data_format=None,\n",
        "#         # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "#         validation_split=0.0)\n",
        "\n",
        "#     # Compute quantities required for feature-wise normalization\n",
        "#     # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    \n",
        "# datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0adBFHnHVYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # start training\n",
        "# from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# checkpoint = ModelCheckpoint(filepath = 'best_model.h5',save_best_only = True,verbose=1)\n",
        "\n",
        "# history = model.fit(datagen.flow(x_train, y_train,batch_size=32),\n",
        "#                                     validation_data=(x_valid, y_valid),\n",
        "#                                     epochs=15,\n",
        "#                                     callbacks=[checkpoint],\n",
        "#                                     verbose=2, \n",
        "#                                     shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "4a1c85173140720d0b72fc693af19f16a3136e35",
        "id": "MAuuWMN_sJEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start training\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath = 'best_model_.h5',save_best_only = True,verbose=1)\n",
        "\n",
        "history = model.fit(x_train,y_train,batch_size=32, epochs = 15,\n",
        "          validation_data=(x_valid,y_valid),\n",
        "          callbacks=[checkpoint],\n",
        "          verbose=2, \n",
        "          shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "61130dbb753426b29de4f838d472920b3414e0a8",
        "id": "s7HBRj3XsJEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's check the accuracy score of the best model on our test set\n",
        "model.load_weights('Best_Basic_Model.h5')\n",
        "score = model.evaluate(x_test,y_test,verbose=0)\n",
        "score[1]\n",
        "# Not bad ! we have an accuracy score of 68% on our test set."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8d5e29c314d1dcead75215914873c31e9ca2e5e0",
        "id": "Kq9vMyNxsJEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets try to visualize the accuracy and loss over the epochs.\n",
        "plt.figure(1)  \n",
        "   \n",
        " # summarize history for accuracy  \n",
        "   \n",
        "plt.subplot(211)  \n",
        "plt.plot(history.history['accuracy'])  \n",
        "plt.plot(history.history['val_accuracy'])  \n",
        "plt.title('Model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "   \n",
        " # summarize history for loss  \n",
        "   \n",
        "plt.subplot(212)  \n",
        "plt.plot(history.history['loss'])  \n",
        "plt.plot(history.history['val_loss'])  \n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_uuid": "38bd5ca0a7594edb4da49a3140b807367f79d3f3",
        "id": "oauch43EsJEn",
        "colab_type": "text"
      },
      "source": [
        "We can see that the accuracy starts increasing till it reaches around epoch 10 and then starts decreasing and just the opposite happens with loss which decreases till epoch 10 and then increases. Somewhere, around apoch 10 we have found our best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEX1YEHAP6yt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXhRduqSP68X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy as sp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy.random import rand\n",
        "pd.options.display.max_colwidth = 600\n",
        "\n",
        "# Scikit Imports\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# Matplot Imports\n",
        "import matplotlib.pyplot as plt\n",
        "params = {'legend.fontsize': 'x-large',\n",
        "          'figure.figsize': (15, 5),\n",
        "          'axes.labelsize': 'x-large',\n",
        "          'axes.titlesize':'x-large',\n",
        "          'xtick.labelsize':'x-large',\n",
        "          'ytick.labelsize':'x-large'}\n",
        "\n",
        "plt.rcParams.update(params)\n",
        "%matplotlib inline\n",
        "\n",
        "# pandas display data frames as tables\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "conyUhAKP6_z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from keras import callbacks\n",
        "from keras import optimizers\n",
        "from keras.datasets import cifar10\n",
        "from keras.engine import Model\n",
        "from keras.applications import vgg16 as vgg\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aKHDoo1P7DQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "EPOCHS = 100\n",
        "NUM_CLASSES = 10\n",
        "LEARNING_RATE = 1e-4\n",
        "MOMENTUM = 0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu_XBQkoP7GY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.transform import resize\n",
        "from skimage import data\n",
        "x = data.camera()\n",
        "X_train = np.array([resize(x, (48, 48)) for x in x_train])\n",
        "X_val = np.array([resize(x, (48, 48)) for x in x_valid])\n",
        "X_test = np.array([resize(x, (48, 48)) for x in x_test])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y07Uzk4oRu71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_model = vgg.VGG16(weights='imagenet', \n",
        "                       include_top=False, \n",
        "                       input_shape=(48, 48, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJ_EambLSqme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Extract the last layer from third block of vgg16 model\n",
        "last = vgg_model.get_layer('block3_pool').output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM9BuzWXSqt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add classification layers on top of it\n",
        "x = GlobalAveragePooling2D()(last)\n",
        "x= BatchNormalization()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.4)(x)\n",
        "pred = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "model = Model(vgg_model.input, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vx0ZVNUASrEy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in vgg_model.layers:\n",
        "     layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vBMVMnLSqqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=LEARNING_RATE),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsNtvI-DSqd8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCfSPVOXTq2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywP6u7gPTxbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_datagen.fit(X_train)\n",
        "train_generator = train_datagen.flow(X_train,\n",
        "                                     y_train, \n",
        "                                     batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPYmeM0VT1B4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "    horizontal_flip=False)\n",
        "\n",
        "val_datagen.fit(X_val)\n",
        "val_generator = val_datagen.flow(X_val,\n",
        "                                 y_valid,\n",
        "                                 batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwNkICAwUj1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_steps_per_epoch = X_train.shape[0] // BATCH_SIZE\n",
        "val_steps_per_epoch = X_val.shape[0] // BATCH_SIZE\n",
        "\n",
        "# history1 = model.fit(train_generator,\n",
        "#                               steps_per_epoch=train_steps_per_epoch,\n",
        "#                               validation_data=val_generator,\n",
        "#                               validation_steps=val_steps_per_epoch,\n",
        "#                               epochs=EPOCHS,\n",
        "#                               verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tyla05HYX3bL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# start training\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint1 = ModelCheckpoint(filepath = 'Best_Model_Pretrained_.h5',save_best_only = True,verbose=1)\n",
        "\n",
        "# history = model.fit(x_train,y_train,batch_size=32, epochs = 20,\n",
        "#           validation_data=(x_valid,y_valid),\n",
        "#           callbacks=[checkpoint],\n",
        "#           verbose=2, shuffle=True)\n",
        "\n",
        "history1 = model.fit(train_generator,\n",
        "                              steps_per_epoch=train_steps_per_epoch,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=val_steps_per_epoch,\n",
        "                              epochs=EPOCHS,\n",
        "                              callbacks=[checkpoint1],\n",
        "                              verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmo7mwd5VuAA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's check the accuracy score of the best model on our test set\n",
        "# model.load_weights('best_model1.h5')\n",
        "score1 = model.evaluate(X_test,y_test,verbose=0)\n",
        "score1[1]\n",
        "# Not bad ! we have an accuracy score of 68% on our test set."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEUkfY0bYQA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets try to visualize the accuracy and loss over the epochs.\n",
        "plt.figure(1)  \n",
        "   \n",
        " # summarize history for accuracy  \n",
        "   \n",
        "plt.subplot(211)  \n",
        "plt.plot(history1.history['accuracy'])  \n",
        "plt.plot(history1.history['val_accuracy'])  \n",
        "plt.title('Model accuracy')  \n",
        "plt.ylabel('accuracy')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "   \n",
        " # summarize history for loss  \n",
        "   \n",
        "plt.subplot(212)  \n",
        "plt.plot(history1.history['loss'])  \n",
        "plt.plot(history1.history['val_loss'])  \n",
        "plt.title('model loss')  \n",
        "plt.ylabel('loss')  \n",
        "plt.xlabel('epoch')  \n",
        "plt.legend(['train', 'test'], loc='upper left')  \n",
        "plt.show()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxJNtxPYiVa8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(35, 7))\n",
        "t = f.suptitle('Deep Neural Net Performance', fontsize=12)\n",
        "f.subplots_adjust(top=0.85, wspace=0.3)\n",
        "\n",
        "epochs = list(range(1,EPOCHS+1))\n",
        "ax1.plot(epochs, history1.history['accuracy'], label='Train Accuracy')\n",
        "ax1.plot(epochs, history1.history['val_accuracy'], label='Validation Accuracy')\n",
        "ax1.set_xticks(epochs)\n",
        "ax1.set_ylabel('Accuracy Value')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_title('Accuracy')\n",
        "l1 = ax1.legend(loc=\"best\")\n",
        "\n",
        "ax2.plot(epochs, history1.history['loss'], label='Train Loss')\n",
        "ax2.plot(epochs, history1.history['val_loss'], label='Validation Loss')\n",
        "ax2.set_xticks(epochs)\n",
        "ax2.set_ylabel('Loss Value')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_title('Loss')\n",
        "l2 = ax2.legend(loc=\"best\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyQrewEWMGzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}